#!/usr/bin/env python3
"""Push-to-talk speech-to-text using faster-whisper.

Hold Right Ctrl to record, release to transcribe and type.
All processing is 100% local — nothing leaves your machine.

By default, the mic is only opened during recording (lazy mode) to
avoid claiming Bluetooth headset profiles between recordings.
Set WHISPER_LAZY_MIC=0 to keep the mic open persistently for a
2-second pre-buffer (captures speech before the key press).
Set WHISPER_DEVICE to pin a specific input device by name or index.
"""

import os
import signal
import subprocess
import sys
import threading
import time
from collections import deque
import numpy as np
import sounddevice as sd
import evdev
from evdev import ecodes
from selectors import DefaultSelector, EVENT_READ

TRIGGER_KEY_NAME = os.environ.get("WHISPER_KEY", "KEY_RIGHTCTRL")
TRIGGER_KEY = getattr(ecodes, TRIGGER_KEY_NAME, None)
if TRIGGER_KEY is None:
    print(f"Unknown key: {TRIGGER_KEY_NAME}", file=sys.stderr, flush=True)
    sys.exit(1)

SAMPLE_RATE = 16000
BLOCK_SIZE = 1024
BEEP_RATE = 48000
MODEL_SIZE = os.environ.get("WHISPER_MODEL", "medium.en")
LANGUAGE = os.environ.get("WHISPER_LANGUAGE", "en")
PRE_BUFFER_SECS = 2
PRE_BUFFER_CHUNKS = (SAMPLE_RATE * PRE_BUFFER_SECS) // BLOCK_SIZE
TRAIL_SECS = 0.5
LAZY_MIC = os.environ.get("WHISPER_LAZY_MIC", "1") == "1"
DEVICE_NAME = os.environ.get("WHISPER_DEVICE")

# Globals
model = None
audio_buffer = []
pre_buffer = deque(maxlen=PRE_BUFFER_CHUNKS)
buffer_lock = threading.Lock()
recording = False
stream = None


def _setup_cuda_paths():
    """Add CUDA libraries from the venv to LD_LIBRARY_PATH if available."""
    venv = os.environ.get("VIRTUAL_ENV") or sys.prefix
    site_pkgs = os.path.join(venv, "lib", f"python{sys.version_info.major}.{sys.version_info.minor}", "site-packages")
    cublas = os.path.join(site_pkgs, "nvidia", "cublas", "lib")
    cudnn = os.path.join(site_pkgs, "nvidia", "cudnn", "lib")
    cuda_libs = ":".join(p for p in (cublas, cudnn) if os.path.isdir(p))
    if cuda_libs:
        existing = os.environ.get("LD_LIBRARY_PATH", "")
        os.environ["LD_LIBRARY_PATH"] = f"{cuda_libs}:{existing}" if existing else cuda_libs


_setup_cuda_paths()


def load_model():
    from faster_whisper import WhisperModel
    print("Loading Whisper model on CUDA...", flush=True)
    try:
        m = WhisperModel(MODEL_SIZE, device="cuda", compute_type="float16")
        print("Model loaded (CUDA float16).", flush=True)
    except Exception as e:
        print(f"CUDA failed ({e}), falling back to CPU...", flush=True)
        m = WhisperModel(MODEL_SIZE, device="cpu", compute_type="int8")
        print("Model loaded (CPU int8).", flush=True)
    return m



def _generate_chirp_wav(kind="start"):
    """Synthesize a soft WALL-E-style electronic chirp.

    Warm, rounded sine tones with gentle frequency modulation and vibrato.
    Single ascending note for start, single descending note for stop.
    Frequency stays in 280-550 Hz (warm, accessible across all age groups).
    """
    import tempfile
    import wave

    if kind == "start":
        # Single soft ascending note
        duration = 0.1
        samples = int(BEEP_RATE * duration)
        t = np.linspace(0, duration, samples, dtype="float32")

        # Ascending sweep 350→550 Hz
        freq = 350 + 200 * (t / duration)
        vibrato = 2 * np.sin(2 * np.pi * 15 * t)
        phase = 2 * np.pi * np.cumsum(freq + vibrato) / BEEP_RATE
        tone = np.sin(phase) + 0.15 * np.sin(2 * phase)

        env = np.sin(np.pi * t / duration) ** 0.6

        mixed = 0.25 * tone * env
    else:
        # Single soft descending note
        duration = 0.1
        samples = int(BEEP_RATE * duration)
        t = np.linspace(0, duration, samples, dtype="float32")

        # Descending sweep 500→280 Hz
        freq = 500 - 220 * (t / duration)
        vibrato = 2 * np.sin(2 * np.pi * 15 * t)
        phase = 2 * np.pi * np.cumsum(freq + vibrato) / BEEP_RATE
        tone = np.sin(phase) + 0.15 * np.sin(2 * phase)

        env = np.sin(np.pi * t / duration) ** 0.6

        mixed = 0.25 * tone * env

    # Write 16-bit WAV
    fd, path = tempfile.mkstemp(suffix=".wav", prefix="whisper-ptt-")
    os.close(fd)
    with wave.open(path, "w") as wf:
        wf.setnchannels(1)
        wf.setsampwidth(2)
        wf.setframerate(BEEP_RATE)
        wf.writeframes((mixed * 32767).astype(np.int16).tobytes())
    return path


# Pre-generate chirp WAV files at import time
_BEEP_START = _generate_chirp_wav("start")
_BEEP_STOP = _generate_chirp_wav("stop")
BEEP_SINK = os.environ.get("WHISPER_BEEP_SINK")


def _find_builtin_sink():
    """Find the built-in audio sink node name for stable beep playback."""
    try:
        r = subprocess.run(
            ["pw-cli", "ls", "Node"],
            capture_output=True, text=True, timeout=2,
        )
        for line in r.stdout.splitlines():
            if "alsa_output" in line and "analog-stereo" in line:
                # Extract node name from the line
                for part in line.split('"'):
                    if part.startswith("alsa_output"):
                        return part
    except Exception:
        pass
    return None


_BUILTIN_SINK = _find_builtin_sink()


def beep(kind="start"):
    """Play a pre-generated beep via pw-play routed to a stable sink.

    Routes to built-in speakers by default to avoid Bluetooth A2DP/HFP
    volume inconsistencies. Override with WHISPER_BEEP_SINK env var.
    """
    wav = _BEEP_START if kind == "start" else _BEEP_STOP
    target = BEEP_SINK or _BUILTIN_SINK
    cmd = ["pw-play", "--volume=1.0", wav]
    if target:
        cmd = ["pw-play", "--volume=1.0", f"--target={target}", wav]
    try:
        subprocess.Popen(
            cmd,
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL,
        )
    except Exception:
        pass


def resolve_device():
    """Resolve WHISPER_DEVICE to a PortAudio device index, or None for default."""
    if not DEVICE_NAME:
        return None
    # Try numeric index first
    try:
        return int(DEVICE_NAME)
    except ValueError:
        pass
    # Search by substring match in device name
    for i, dev in enumerate(sd.query_devices()):
        if dev["max_input_channels"] > 0 and DEVICE_NAME.lower() in dev["name"].lower():
            return i
    print(f"Audio device not found: {DEVICE_NAME}", file=sys.stderr, flush=True)
    print("Available input devices:", file=sys.stderr, flush=True)
    for i, dev in enumerate(sd.query_devices()):
        if dev["max_input_channels"] > 0:
            print(f"  {i}: {dev['name']}", file=sys.stderr, flush=True)
    sys.exit(1)


def open_mic_stream(device_index):
    """Open and start a mic input stream."""
    s = sd.InputStream(
        samplerate=SAMPLE_RATE,
        channels=1,
        dtype="float32",
        callback=audio_callback,
        blocksize=BLOCK_SIZE,
        device=device_index,
    )
    s.start()
    return s


def close_mic_stream(s):
    """Stop and close a mic input stream."""
    if s is None:
        return
    try:
        s.stop()
        s.close()
    except Exception:
        pass


def find_keyboards():
    devices = []
    for path in evdev.list_devices():
        dev = evdev.InputDevice(path)
        caps = dev.capabilities()
        keys = caps.get(ecodes.EV_KEY, [])
        if TRIGGER_KEY in keys:
            try:
                num = int(path.split("event")[-1])
                if num > 100:
                    dev.close()
                    continue
            except ValueError:
                pass
            devices.append(dev)
    return devices


def audio_callback(indata, frames, time_info, status):
    chunk = indata[:, 0].copy()
    with buffer_lock:
        if recording:
            audio_buffer.append(chunk)
        else:
            pre_buffer.append(chunk)


def start_recording(device_index):
    global recording, stream
    beep("start")
    if LAZY_MIC:
        stream = open_mic_stream(device_index)
    with buffer_lock:
        audio_buffer.clear()
        if not LAZY_MIC:
            audio_buffer.extend(pre_buffer)
        pre_buffer.clear()
        recording = True


def stop_and_transcribe():
    global recording, stream

    beep("stop")
    time.sleep(TRAIL_SECS)

    with buffer_lock:
        recording = False
        if not audio_buffer:
            print("  no audio captured", flush=True)
            if LAZY_MIC:
                close_mic_stream(stream)
                stream = None
            return
        audio = np.concatenate(audio_buffer)
        audio_buffer.clear()

    if LAZY_MIC:
        close_mic_stream(stream)
        stream = None

    duration = len(audio) / SAMPLE_RATE
    if duration < 0.3:
        print(f"  too short ({duration:.1f}s), skipping", flush=True)
        return

    print(f"  transcribing {duration:.1f}s...", flush=True)
    t0 = time.time()

    segments, info = model.transcribe(
        audio,
        beam_size=5,
        language=LANGUAGE,
        vad_filter=True,
        vad_parameters=dict(min_silence_duration_ms=500),
    )

    text = " ".join(seg.text.strip() for seg in segments).strip()
    elapsed = time.time() - t0

    if not text:
        print(f"  no speech detected ({elapsed:.1f}s)", flush=True)
        return

    print(f"  [{elapsed:.1f}s] {text}", flush=True)

    # Copy to clipboard (wl-copy stays alive to serve paste requests)
    try:
        proc = subprocess.Popen(["wl-copy", "--", text])
        proc.wait(timeout=3)
    except subprocess.TimeoutExpired:
        proc.kill()
        proc.wait()
    except Exception:
        pass

    # Type text directly
    time.sleep(0.3)
    try:
        subprocess.run(
            ["ydotool", "type", "--delay", "50", "--key-delay", "4", "--", text],
            timeout=30, capture_output=True
        )
    except Exception as e:
        print(f"  type error: {e}", file=sys.stderr, flush=True)


def main():
    global model, stream

    keyboards = find_keyboards()
    if not keyboards:
        print("No keyboards found. Are you in the 'input' group?",
              file=sys.stderr, flush=True)
        sys.exit(1)

    model = load_model()
    device_index = resolve_device()

    if not LAZY_MIC:
        stream = open_mic_stream(device_index)

    mode = "lazy mic" if LAZY_MIC else "persistent mic"
    dev_label = DEVICE_NAME or "default"
    print(f"Push-to-talk ready ({mode}, device: {dev_label}, hold {TRIGGER_KEY_NAME}):",
          flush=True)
    for kb in keyboards:
        print(f"  {kb.path}: {kb.name}", flush=True)

    selector = DefaultSelector()
    for kb in keyboards:
        selector.register(kb, EVENT_READ)

    is_recording = False

    def cleanup(signum=None, frame=None):
        close_mic_stream(stream)
        for kb in keyboards:
            try:
                selector.unregister(kb)
                kb.close()
            except Exception:
                pass
        selector.close()
        sys.exit(0)

    signal.signal(signal.SIGTERM, cleanup)
    signal.signal(signal.SIGINT, cleanup)

    try:
        while True:
            for key, mask in selector.select():
                device = key.fileobj
                try:
                    for event in device.read():
                        if event.type != ecodes.EV_KEY:
                            continue
                        if event.value == 2:
                            continue

                        if event.code == TRIGGER_KEY:
                            if event.value == 1 and not is_recording:
                                is_recording = True
                                start_recording(device_index)
                                print("  recording...", flush=True)
                            elif event.value == 0 and is_recording:
                                is_recording = False
                                print("  released", flush=True)
                                threading.Thread(
                                    target=stop_and_transcribe,
                                    daemon=True
                                ).start()
                except OSError:
                    pass
    except KeyboardInterrupt:
        pass
    finally:
        cleanup()


if __name__ == "__main__":
    main()
