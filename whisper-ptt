#!/usr/bin/env python3
"""Push-to-talk speech-to-text using faster-whisper.

Hold Right Ctrl to record, release to transcribe and type.
All processing is 100% local — nothing leaves your machine.

By default, the mic is only opened during recording (lazy mode) to
avoid claiming Bluetooth headset profiles between recordings.
Set WHISPER_LAZY_MIC=0 to keep the mic open persistently for a
2-second pre-buffer (captures speech before the key press).
Set WHISPER_DEVICE to pin a specific input device by name or index.
"""

import os
import signal
import subprocess
import sys
import threading
import time
from collections import deque
import numpy as np
import sounddevice as sd
import evdev
from evdev import ecodes
from selectors import DefaultSelector, EVENT_READ

TRIGGER_KEY_NAME = os.environ.get("WHISPER_KEY", "KEY_RIGHTCTRL")
TRIGGER_KEY = getattr(ecodes, TRIGGER_KEY_NAME, None)
if TRIGGER_KEY is None:
    print(f"Unknown key: {TRIGGER_KEY_NAME}", file=sys.stderr, flush=True)
    sys.exit(1)

SAMPLE_RATE = 16000
BLOCK_SIZE = 1024
BEEP_RATE = 48000
MODEL_SIZE = os.environ.get("WHISPER_MODEL", "medium.en")
LANGUAGE = os.environ.get("WHISPER_LANGUAGE", "en")
PRE_BUFFER_SECS = 2
PRE_BUFFER_CHUNKS = (SAMPLE_RATE * PRE_BUFFER_SECS) // BLOCK_SIZE
TRAIL_SECS = 0.5
LAZY_MIC = os.environ.get("WHISPER_LAZY_MIC", "1") == "1"
DEVICE_NAME = os.environ.get("WHISPER_DEVICE")

# Globals
model = None
audio_buffer = []
pre_buffer = deque(maxlen=PRE_BUFFER_CHUNKS)
buffer_lock = threading.Lock()
recording = False
stream = None


def _setup_cuda_paths():
    """Add CUDA libraries from the venv to LD_LIBRARY_PATH if available."""
    venv = os.environ.get("VIRTUAL_ENV") or sys.prefix
    site_pkgs = os.path.join(venv, "lib", f"python{sys.version_info.major}.{sys.version_info.minor}", "site-packages")
    cublas = os.path.join(site_pkgs, "nvidia", "cublas", "lib")
    cudnn = os.path.join(site_pkgs, "nvidia", "cudnn", "lib")
    cuda_libs = ":".join(p for p in (cublas, cudnn) if os.path.isdir(p))
    if cuda_libs:
        existing = os.environ.get("LD_LIBRARY_PATH", "")
        os.environ["LD_LIBRARY_PATH"] = f"{cuda_libs}:{existing}" if existing else cuda_libs


_setup_cuda_paths()


def load_model():
    from faster_whisper import WhisperModel
    print("Loading Whisper model on CUDA...", flush=True)
    try:
        m = WhisperModel(MODEL_SIZE, device="cuda", compute_type="float16")
        print("Model loaded (CUDA float16).", flush=True)
    except Exception as e:
        print(f"CUDA failed ({e}), falling back to CPU...", flush=True)
        m = WhisperModel(MODEL_SIZE, device="cpu", compute_type="int8")
        print("Model loaded (CPU int8).", flush=True)
    return m


def beep(freq=880, duration=0.06):
    """Play a soft, rounded tone for audio feedback."""
    samples = int(BEEP_RATE * duration)
    t = np.linspace(0, duration, samples, endpoint=False, dtype="float32")
    # Blend fundamental with a softer octave above for a warmer sound
    tone = np.sin(2 * np.pi * freq * t) + 0.3 * np.sin(2 * np.pi * freq * 2 * t)
    # Smooth envelope (raised cosine) — no harsh attack or cutoff
    envelope = 0.5 * (1 - np.cos(2 * np.pi * np.linspace(0, 1, samples)))
    tone = 0.04 * tone * envelope
    try:
        sd.play(tone.astype("float32"), samplerate=BEEP_RATE, blocksize=1024)
    except Exception:
        pass


def resolve_device():
    """Resolve WHISPER_DEVICE to a PortAudio device index, or None for default."""
    if not DEVICE_NAME:
        return None
    # Try numeric index first
    try:
        return int(DEVICE_NAME)
    except ValueError:
        pass
    # Search by substring match in device name
    for i, dev in enumerate(sd.query_devices()):
        if dev["max_input_channels"] > 0 and DEVICE_NAME.lower() in dev["name"].lower():
            return i
    print(f"Audio device not found: {DEVICE_NAME}", file=sys.stderr, flush=True)
    print("Available input devices:", file=sys.stderr, flush=True)
    for i, dev in enumerate(sd.query_devices()):
        if dev["max_input_channels"] > 0:
            print(f"  {i}: {dev['name']}", file=sys.stderr, flush=True)
    sys.exit(1)


def open_mic_stream(device_index):
    """Open and start a mic input stream."""
    s = sd.InputStream(
        samplerate=SAMPLE_RATE,
        channels=1,
        dtype="float32",
        callback=audio_callback,
        blocksize=BLOCK_SIZE,
        device=device_index,
    )
    s.start()
    return s


def close_mic_stream(s):
    """Stop and close a mic input stream."""
    if s is None:
        return
    try:
        s.stop()
        s.close()
    except Exception:
        pass


def find_keyboards():
    devices = []
    for path in evdev.list_devices():
        dev = evdev.InputDevice(path)
        caps = dev.capabilities()
        keys = caps.get(ecodes.EV_KEY, [])
        if TRIGGER_KEY in keys:
            try:
                num = int(path.split("event")[-1])
                if num > 100:
                    dev.close()
                    continue
            except ValueError:
                pass
            devices.append(dev)
    return devices


def audio_callback(indata, frames, time_info, status):
    chunk = indata[:, 0].copy()
    with buffer_lock:
        if recording:
            audio_buffer.append(chunk)
        else:
            pre_buffer.append(chunk)


def start_recording(device_index):
    global recording, stream
    beep(freq=880)
    if LAZY_MIC:
        stream = open_mic_stream(device_index)
    with buffer_lock:
        audio_buffer.clear()
        if not LAZY_MIC:
            audio_buffer.extend(pre_buffer)
        pre_buffer.clear()
        recording = True


def stop_and_transcribe():
    global recording, stream

    beep(freq=440)
    time.sleep(TRAIL_SECS)

    with buffer_lock:
        recording = False
        if not audio_buffer:
            print("  no audio captured", flush=True)
            if LAZY_MIC:
                close_mic_stream(stream)
                stream = None
            return
        audio = np.concatenate(audio_buffer)
        audio_buffer.clear()

    if LAZY_MIC:
        close_mic_stream(stream)
        stream = None

    duration = len(audio) / SAMPLE_RATE
    if duration < 0.3:
        print(f"  too short ({duration:.1f}s), skipping", flush=True)
        return

    print(f"  transcribing {duration:.1f}s...", flush=True)
    t0 = time.time()

    segments, info = model.transcribe(
        audio,
        beam_size=5,
        language=LANGUAGE,
        vad_filter=True,
        vad_parameters=dict(min_silence_duration_ms=500),
    )

    text = " ".join(seg.text.strip() for seg in segments).strip()
    elapsed = time.time() - t0

    if not text:
        print(f"  no speech detected ({elapsed:.1f}s)", flush=True)
        return

    print(f"  [{elapsed:.1f}s] {text}", flush=True)

    # Copy to clipboard (wl-copy stays alive to serve paste requests)
    try:
        proc = subprocess.Popen(["wl-copy", "--", text])
        proc.wait(timeout=3)
    except subprocess.TimeoutExpired:
        proc.kill()
        proc.wait()
    except Exception:
        pass

    # Type text directly
    time.sleep(0.3)
    try:
        subprocess.run(
            ["ydotool", "type", "--delay", "50", "--key-delay", "4", "--", text],
            timeout=30, capture_output=True
        )
    except Exception as e:
        print(f"  type error: {e}", file=sys.stderr, flush=True)


def main():
    global model, stream

    keyboards = find_keyboards()
    if not keyboards:
        print("No keyboards found. Are you in the 'input' group?",
              file=sys.stderr, flush=True)
        sys.exit(1)

    model = load_model()
    device_index = resolve_device()

    if not LAZY_MIC:
        stream = open_mic_stream(device_index)

    mode = "lazy mic" if LAZY_MIC else "persistent mic"
    dev_label = DEVICE_NAME or "default"
    print(f"Push-to-talk ready ({mode}, device: {dev_label}, hold {TRIGGER_KEY_NAME}):",
          flush=True)
    for kb in keyboards:
        print(f"  {kb.path}: {kb.name}", flush=True)

    selector = DefaultSelector()
    for kb in keyboards:
        selector.register(kb, EVENT_READ)

    is_recording = False

    def cleanup(signum=None, frame=None):
        close_mic_stream(stream)
        for kb in keyboards:
            try:
                selector.unregister(kb)
                kb.close()
            except Exception:
                pass
        selector.close()
        sys.exit(0)

    signal.signal(signal.SIGTERM, cleanup)
    signal.signal(signal.SIGINT, cleanup)

    try:
        while True:
            for key, mask in selector.select():
                device = key.fileobj
                try:
                    for event in device.read():
                        if event.type != ecodes.EV_KEY:
                            continue
                        if event.value == 2:
                            continue

                        if event.code == TRIGGER_KEY:
                            if event.value == 1 and not is_recording:
                                is_recording = True
                                start_recording(device_index)
                                print("  recording...", flush=True)
                            elif event.value == 0 and is_recording:
                                is_recording = False
                                print("  released", flush=True)
                                threading.Thread(
                                    target=stop_and_transcribe,
                                    daemon=True
                                ).start()
                except OSError:
                    pass
    except KeyboardInterrupt:
        pass
    finally:
        cleanup()


if __name__ == "__main__":
    main()
